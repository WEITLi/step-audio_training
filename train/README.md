# Step-Audio-EditX LLM + Flow å¾®è°ƒè®­ç»ƒç³»ç»Ÿ

> è½»é‡åŒ–å¾®è°ƒæ¨¡å—ï¼Œæ”¯æŒè¯­éŸ³å…‹éš†å’ŒéŸ³é¢‘ç¼–è¾‘ä»»åŠ¡çš„ LLM (LoRA) å’Œ Flow (è§£ç å™¨) å¾®è°ƒ

## ğŸ“ ç›®å½•ç»“æ„

```
train/
â”œâ”€â”€ configs/              # è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ finetune_llm_flow.yaml
â”œâ”€â”€ dataset/              # æ•°æ®é›†æ¨¡å—
â”‚   â”œâ”€â”€ processor.py      # æ•°æ®å¤„ç†å™¨
â”‚   â””â”€â”€ dataset.py        # Dataset å®ç°
â”œâ”€â”€ trainer/              # è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ model_adapter.py  # æ¨¡å‹é€‚é…å™¨
â”‚   â””â”€â”€ train_loop.py     # è®­ç»ƒå¾ªç¯
â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ config_utils.py
â”‚   â”œâ”€â”€ train_utils.py
â”‚   â””â”€â”€ data_utils.py
â”œâ”€â”€ tools/                # é¢„å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ extract_speech_token.py
â”‚   â”œâ”€â”€ extract_embedding.py
â”‚   â”œâ”€â”€ make_parquet.py
â”‚   â””â”€â”€ prepare_data.sh
â””â”€â”€ docs/                 # æ–‡æ¡£
    â””â”€â”€ data_preparation.md
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r train/requirements.txt
```

### 2. å‡†å¤‡æ•°æ®

#### 2.1 å‡†å¤‡åŸºç¡€æ–‡ä»¶

åœ¨æºç›®å½•ï¼ˆä¾‹å¦‚ `data/raw`ï¼‰åˆ›å»ºä»¥ä¸‹æ–‡ä»¶ï¼š

**wav.scp** (éŸ³é¢‘åˆ—è¡¨):
```
utt001 /path/to/audio001.wav
utt002 /path/to/audio002.wav
```

**text** (æ–‡æœ¬è½¬å½•):
```
utt001 ä½ å¥½ä¸–ç•Œ
utt002 Hello world
```

**utt2spk** (è¯´è¯äººæ˜ å°„):
```
utt001 spk001
utt002 spk002
```

#### 2.2 è¿è¡Œé¢„å¤„ç†

```bash
# ä¸€é”®é¢„å¤„ç†è„šæœ¬
bash train/tools/prepare_data.sh data/raw data/parquet
```

æˆ–è€…æ‰‹åŠ¨æ‰§è¡Œï¼š

```bash
# æ­¥éª¤ 1: æå– speaker embedding
python train/tools/extract_embedding.py \
    --wav_scp data/raw/wav.scp \
    --utt2spk data/raw/utt2spk \
    --onnx_path pretrained_models/Step-Audio-EditX/CosyVoice-300M-25Hz/campplus.onnx \
    --output_dir data/raw

# æ­¥éª¤ 2: æå– speech token
python train/tools/extract_speech_token.py \
    --wav_scp data/raw/wav.scp \
    --tokenizer_path pretrained_models/Step-Audio-Tokenizer \
    --output data/raw/utt2speech_token.pt \
    --model_source local

# æ­¥éª¤ 3: æ‰“åŒ…æˆ parquet
python train/tools/make_parquet.py \
    --src_dir data/raw \
    --des_dir data/parquet \
    --num_utts_per_parquet 1000
```

**è¾“å‡º**ï¼š`data/parquet/data.list` (parquet æ–‡ä»¶åˆ—è¡¨)

### 3. é…ç½®è®­ç»ƒå‚æ•°

ç¼–è¾‘ `train/configs/finetune_llm_flow.yaml`:

```yaml
# æ•°æ®è·¯å¾„
data:
  train_data: "./data/train/parquet/data.list"
  cv_data: "./data/dev/parquet/data.list"

# è®­ç»ƒæ¨¡å¼
basic:
  train_mode: "both"  # "llm" | "flow" | "both"
```

### 4. å¼€å§‹è®­ç»ƒ

```bash
# è®­ç»ƒæ¨¡å¼ 1: ä»… Flow æ¨¡å‹ï¼ˆæ¨èå¿«é€Ÿå¾®è°ƒï¼‰
python finetune_demo.py --mode flow

# è®­ç»ƒæ¨¡å¼ 2: ä»… LLM æ¨¡å‹
python finetune_demo.py --mode llm

# è®­ç»ƒæ¨¡å¼ 3: åˆ†é˜¶æ®µè®­ç»ƒï¼ˆå®Œæ•´è®­ç»ƒï¼‰
python finetune_demo.py --mode both
```

---

## ğŸ“Š æ•°æ®æ ¼å¼

### Parquet æ•°æ®ç»“æ„

æ¯ä¸ªæ ·æœ¬åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```python
{
    'utt': 'utterance_id',           # æ ·æœ¬ ID
    'wav': '/path/to/audio.wav',     # éŸ³é¢‘è·¯å¾„
    'audio_data': b'...',             # éŸ³é¢‘äºŒè¿›åˆ¶æ•°æ®
    'text': 'ä½ å¥½ä¸–ç•Œ',               # æ–‡æœ¬å†…å®¹
    'spk': 'speaker_001',             # è¯´è¯äºº ID
    'utt_embedding': [...],           # 192-dim utterance embedding
    'spk_embedding': [...],           # 192-dim speaker embedding
    'speech_token': [...],            # ç¦»æ•£è¯­éŸ³ token
}
```

### å…³é”®ç‚¹

- âœ… **ä»…éœ€è¦å•ä¸ªéŸ³é¢‘** + æ–‡æœ¬ï¼Œæ— éœ€é…å¯¹æ•°æ®
- âœ… **Speech token é¢„æå–**ï¼ˆç¦»çº¿å®Œæˆï¼Œæé«˜è®­ç»ƒé€Ÿåº¦ï¼‰
- âœ… **Speaker embedding é¢„æå–**ï¼ˆä½¿ç”¨ FunASR Campplusï¼‰
- âœ… **Parquet æ ¼å¼**ï¼ˆé«˜æ•ˆ I/Oï¼‰

---

## ğŸ¯ è®­ç»ƒæ¨¡å¼

### æ¨¡å¼ 1: flow - ä»…è®­ç»ƒ Flow è§£ç å™¨
```bash
python finetune_demo.py --mode flow
```
- è®­ç»ƒå†…å®¹ï¼šFlow è§£ç å™¨
- è®­ç»ƒæ—¶é—´ï¼š1-2 å¤©
- é€‚ç”¨åœºæ™¯ï¼šæ”¹å–„éŸ³è´¨ã€mel ç”Ÿæˆ

### æ¨¡å¼ 2: llm - ä»…è®­ç»ƒ LLM
```bash
python finetune_demo.py --mode llm
```
- è®­ç»ƒå†…å®¹ï¼šLLM LoRA
- è®­ç»ƒæ—¶é—´ï¼š1-2 å¤©
- é€‚ç”¨åœºæ™¯ï¼šæ”¹å–„ token ç”Ÿæˆ

### æ¨¡å¼ 3: both - åˆ†é˜¶æ®µè®­ç»ƒ
```bash
python finetune_demo.py --mode both
```
- é˜¶æ®µ 1ï¼šLLM å•ç‹¬å¾®è°ƒ (25 epochs)
- é˜¶æ®µ 2ï¼šFlow å•ç‹¬å¾®è°ƒ (25 epochs)
- é˜¶æ®µ 3ï¼šè”åˆå¾®è°ƒ (5 epochsï¼Œå¯é€‰)
- è®­ç»ƒæ—¶é—´ï¼š3-5 å¤©
- é€‚ç”¨åœºæ™¯ï¼šç«¯åˆ°ç«¯ä¼˜åŒ–

---

## ğŸ’¾ ä½¿ç”¨å¾®è°ƒæ¨¡å‹

```python
from tts import StepAudioTTS
from tokenizer import StepAudioTokenizer
from model_loader import ModelSource

# åˆå§‹åŒ–
tokenizer = StepAudioTokenizer(
    encoder_path="pretrained_models/Step-Audio-EditX",
    model_source=ModelSource.LOCAL
)

tts = StepAudioTTS(
    model_path="pretrained_models/Step-Audio-EditX",
    audio_tokenizer=tokenizer,
    model_source=ModelSource.LOCAL
)

# åŠ è½½å¾®è°ƒæƒé‡
tts.load_finetuned_model(
    llm_ckpt_path="ckpt/finetune/llm_best.pt",
    flow_ckpt_path="ckpt/finetune/flow_best.pt"
)

# æ¨ç†
audio, sr = tts.clone(
    prompt_wav_path="prompt.wav",
    prompt_text="å‚è€ƒæ–‡æœ¬",
    target_text="ç›®æ ‡æ–‡æœ¬"
)
```

---

## âš™ï¸ é«˜çº§é…ç½®

### è°ƒæ•´ LoRA å‚æ•°

```yaml
model:
  llm:
    lora_r: 8              # LoRA rank
    lora_alpha: 32
    lora_dropout: 0.05
```

### è°ƒæ•´è®­ç»ƒé˜¶æ®µ

```yaml
stage:
  stage1_epochs: 30      # LLM
  stage2_epochs: 30      # Flow
  stage3_epochs: 10      # è”åˆ
```

### å‡å°‘æ˜¾å­˜å ç”¨

```yaml
optim:
  accum_grad: 8          # æ¢¯åº¦ç´¯ç§¯

data:
  max_frames_in_batch: 1000  # å‡å° batch size
```

---

## ğŸ› æ•…éšœæ’é™¤

### CUDA Out of Memory
- å¢åŠ  `accum_grad`
- å‡å° `max_frames_in_batch`
- å‡å° `lora_r`

### Speech Token æå–å¤ªæ…¢
- ä½¿ç”¨ GPU
- åˆ†æ‰¹å¤„ç†

### Parquet æ–‡ä»¶æŸå
- æ£€æŸ¥åŸå§‹éŸ³é¢‘å®Œæ•´æ€§
- é‡æ–°è¿è¡Œ `make_parquet.py`

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- [æ•°æ®å‡†å¤‡æŒ‡å—](train/docs/data_preparation.md)
- [è®­ç»ƒæ¨¡å¼è¯´æ˜](train/TRAINING_MODES.md)

---

## âš ï¸ é‡è¦è¯´æ˜

1. **è®­ç»ƒæ•°æ®ç®€å•**ï¼šåªéœ€ (éŸ³é¢‘ + æ–‡æœ¬ + è¯´è¯äººID)
2. **é¢„å¤„ç†æ˜¯å…³é”®**ï¼šToken å’Œ embedding å¿…é¡»é¢„æå–
3. **ç¼–è¾‘èƒ½åŠ›æ¥è‡ª SFT/PPO**ï¼šåŸºç¡€è®­ç»ƒåªå­¦ä¹ ç”Ÿæˆï¼Œä¸å­¦ä¹ ç¼–è¾‘
4. **ä¿ç•™æ¨ç†é€»è¾‘**ï¼šå¾®è°ƒæƒé‡å®Œå…¨å…¼å®¹åŸæ¨ç† API

---

## ğŸ“ License

æœ¬æ¨¡å—éµå¾ª Step-Audio-EditX ä¸»ä»“åº“çš„ License
